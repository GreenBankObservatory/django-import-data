{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data into Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that you want to import a bunch of data into Django. To keep things simple, we'll say this is information about people -- names, addresses, etc.\n",
    "\n",
    "In the simplest case you could simply assume that all of your source column names match your destination field names, and do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ = Person.objects.all().delete()\n",
    "__ = Case.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def handle_form(data, form_class):\n",
    "    form = form_class(data)\n",
    "    if form.is_valid():\n",
    "        return form.save()\n",
    "    \n",
    "    raise ValueError(form.errors.as_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: OrderedDict([('name', 'Thomas'), ('phone', '123456789'), ('email', 'thomas@thomas.com')])\n",
      "Created Person: Thomas; 123456789; thomas@thomas.com\n",
      "Row: OrderedDict([('name', 'Bill'), ('phone', '758586998'), ('email', 'foo@bar.com')])\n",
      "Created Person: Bill; 758586998; foo@bar.com\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "from cases.forms import PersonForm\n",
    "\n",
    "def create_person(data):\n",
    "    person = handle_form(data, PersonForm)\n",
    "    print(f\"Created Person: {person}\")\n",
    "    return person\n",
    "\n",
    "data = \"\"\"name,phone,email\n",
    "Thomas,123456789,thomas@thomas.com\n",
    "Bill,758586998,foo@bar.com\n",
    "\"\"\"\n",
    "\n",
    "for row in csv.DictReader(StringIO(data)):\n",
    "    print(f\"Row: {row}\")\n",
    "    person = create_person(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but what if they *don't* match? Easy, right? You can simply create a mapping of source field/column to destination field. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: OrderedDict([('name', 'Thomas'), ('phone', '123456789'), ('email', 'thomas@thomas.com')])\n",
      "Created Person: Thomas; 123456789; thomas@thomas.com\n",
      "Row: OrderedDict([('name', 'Bill'), ('phone', '758586998'), ('email', 'foo@bar.com')])\n",
      "Created Person: Bill; 758586998; foo@bar.com\n"
     ]
    }
   ],
   "source": [
    "def gen_reader(data, from_field_aliases):\n",
    "    reader = csv.DictReader(StringIO(data))\n",
    "    reader.fieldnames = [from_field_aliases[fieldname] for fieldname in reader.fieldnames]\n",
    "    return reader\n",
    "\n",
    "def process_csv(data, from_field_aliases):\n",
    "    \"\"\"Given a string representation of a CSV file, handle its contents\"\"\"\n",
    "    reader = gen_reader(data, from_field_aliases)\n",
    "    for row in reader:\n",
    "        print(f\"Row: {row}\")\n",
    "        person = create_person(row)\n",
    "\n",
    "# Note that we are changing the headers here!\n",
    "#         â†“ changed\n",
    "data = \"\"\"full_name,phone_number,email\n",
    "Thomas,123456789,thomas@thomas.com\n",
    "Bill,758586998,foo@bar.com\n",
    "\"\"\"\n",
    "\n",
    "from_field_aliases = {\n",
    "    # from_field: alias\n",
    "    \"full_name\": \"name\",\n",
    "    \"phone_number\": \"phone\",\n",
    "    \"email\": \"email\"\n",
    "}\n",
    "\n",
    "\n",
    "process_csv(data, from_field_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, this works just fine! But, what if we have data in many different files, often with different headers for the same columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: OrderedDict([('name', 'Thomas'), ('phone', '123456789'), ('email', 'thomas@thomas.com')])\n",
      "Created Person: Thomas; 123456789; thomas@thomas.com\n",
      "Row: OrderedDict([('name', 'Bill'), ('phone', '758586998'), ('email', 'foo@bar.com')])\n",
      "Created Person: Bill; 758586998; foo@bar.com\n"
     ]
    }
   ],
   "source": [
    "# Data from the first CSV file\n",
    "data1 = \"\"\"full_name,phone_number,email\n",
    "Thomas,123456789,thomas@thomas.com\n",
    "\"\"\"\n",
    "\n",
    "# Data from the second CSV file\n",
    "data2 = \"\"\"NAME,PHONE,EMAIL\n",
    "Bill,758586998,foo@bar.com\n",
    "\"\"\"\n",
    "\n",
    "# We'll need to accommodate the fact that we have different headers representing the same thing.\n",
    "# But, we can simply add more aliases to handle this\n",
    "from_field_aliases = {\n",
    "    \"full_name\": \"name\",\n",
    "    \"NAME\": \"name\",\n",
    "    \"phone_number\": \"phone\",\n",
    "    \"PHONE\": \"phone\",\n",
    "    \"email\": \"email\",\n",
    "    \"EMAIL\": \"email\",\n",
    "    \"letter\": \"attachment\",\n",
    "    \"LETTER\": \"attachment\",\n",
    "    \"case_num\": \"case_num\",\n",
    "    \"CASE\": \"case_num\",\n",
    "}\n",
    "\n",
    "for data in [data1, data2]:\n",
    "    process_csv(data, from_field_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's *very* verbose! We can actually \"compress\" this dict so that it can be represented more cleanly, although we'll need to invert the mapping and use `{from_field: [possible_from_fields]}` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are our expanded aliases:\n",
      "{'CASE': 'case_num',\n",
      " 'EMAIL': 'email',\n",
      " 'LETTER': 'attachment',\n",
      " 'NAME': 'name',\n",
      " 'PHONE': 'phone',\n",
      " 'case_num': 'case_num',\n",
      " 'email': 'email',\n",
      " 'full_name': 'name',\n",
      " 'letter': 'attachment',\n",
      " 'phone_number': 'phone'}\n",
      "And now to process the data, we do the same as before:\n",
      "Row: OrderedDict([('name', 'Thomas'), ('phone', '123456789'), ('email', 'thomas@thomas.com')])\n",
      "Created Person: Thomas; 123456789; thomas@thomas.com\n",
      "Row: OrderedDict([('name', 'Bill'), ('phone', '758586998'), ('email', 'foo@bar.com')])\n",
      "Created Person: Bill; 758586998; foo@bar.com\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "compressed_from_field_aliases = {\n",
    "    # from_field: (alias1, alias2, ...)\n",
    "    \"name\": (\"full_name\", \"NAME\"),\n",
    "    \"phone\": (\"phone_number\", \"PHONE\"),\n",
    "    \"email\": (\"email\", \"EMAIL\"),\n",
    "    \"attachment\": (\"letter\", \"LETTER\"),\n",
    "    \"case_num\": (\"case_num\", \"CASE\"),\n",
    "}\n",
    "\n",
    "def invert_aliases(aliases_):\n",
    "    \"\"\"Given map of format {field, aliases, ...}, return one of format {alias: field, ...}\"\"\"\n",
    "    return {alias: field for field, aliases in aliases_.items() for alias in aliases}\n",
    "\n",
    "from_field_aliases = invert_aliases(compressed_from_field_aliases)\n",
    "print(\"These are our expanded aliases:\")\n",
    "pprint(from_field_aliases)\n",
    "\n",
    "print(\"And now to process the data, we do the same as before:\")\n",
    "for data in [data1, data2]:\n",
    "    process_csv(data, from_field_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about messy data *values*? For example, what if we encounter case numbers that cannot be converted to `float`? Well, we _could_ use Django's built-in form validation to handle this... but this quickly gets very messy once we get into more complicated cases (as we'll see soon).\n",
    "\n",
    "So, instead, we'll introduce the concept of a \"converter\" function that handles this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are our expanded aliases:\n",
      "{'CASE': 'case_num', 'case_num': 'case_num'}\n",
      "And now to process the data, we do the same as before:\n",
      "Row: OrderedDict([('case_num', 'CASE#123123')])\n",
      "converted {'case_num': '123123'}\n",
      "Created Case: #123123 (None)\n",
      "Row: OrderedDict([('case_num', 'CASE#456456')])\n",
      "converted {'case_num': '456456'}\n",
      "Created Case: #456456 (None)\n"
     ]
    }
   ],
   "source": [
    "data1 = \"\"\"case_num\n",
    "CASE#123123\n",
    "\"\"\"\n",
    "data2 = \"\"\"CASE\n",
    "CASE#456456\n",
    "\"\"\"\n",
    "\n",
    "from cases.forms import CaseForm\n",
    "\n",
    "def create_case(data):\n",
    "    case = handle_form(data, CaseForm)\n",
    "    print(f\"Created Case: {case}\")\n",
    "    return case\n",
    "\n",
    "# Update our process_csv function to:\n",
    "# * process Cases instead of People\n",
    "# * convert any fields that need converting before sending them to the CaseForm\n",
    "def process_csv(data, from_field_aliases):\n",
    "    \"\"\"Given a string representation of a CSV file, handle its contents\"\"\"\n",
    "    reader = gen_reader(data, from_field_aliases)\n",
    "    for row in reader:\n",
    "        print(f\"Row: {row}\")\n",
    "        # Convert all fields that have converters\n",
    "        converted = {field: converters[field](value) for field, value in row.items() if field in converters}\n",
    "        print(\"converted\", converted)\n",
    "        # Merge converted data with row data, overwriting any \"old\" data in the row\n",
    "        case = create_case({**row, **converted})\n",
    "\n",
    "    \n",
    "compressed_from_field_aliases = {\n",
    "    \"case_num\": (\"case_num\", \"CASE\"),\n",
    "}\n",
    "\n",
    "converters = {\n",
    "    \"case_num\": lambda case_num: case_num.strip(\"CASE#\"),\n",
    "}\n",
    "\n",
    "from_field_aliases = invert_aliases(compressed_from_field_aliases)\n",
    "print(\"These are our expanded aliases:\")\n",
    "pprint(from_field_aliases)\n",
    "\n",
    "print(\"And now to process the data, we do the same as before:\")\n",
    "for data in [data1, data2]:\n",
    "    process_csv(data, from_field_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works well enough, although we do have a bit of redundancy now -- two maps instead of a single map. Further, we still can't deal with more complicated mappings. If, for example, we wanted to combine latitude and longitude into a single field, location, how might we do that?\n",
    "\n",
    "The primary change is that we need to move from the paradigm of \"do something for each field in each row\" to \"do something for each mapping, for each row\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And now to process the data, we do the same as before:\n",
      "Row: OrderedDict([('latitude', '38.1'), ('longitude', '72.8')])\n",
      "converted {'location': '38.1,72.8'}\n",
      "data:  {'latitude': '38.1', 'longitude': '72.8', 'location': '38.1,72.8'}\n",
      "Created Structure: 38.1,72.8\n",
      "Row: OrderedDict([('latitude', '38.2'), ('longitude', '78.5')])\n",
      "converted {'location': '38.2,78.5'}\n",
      "data:  {'latitude': '38.2', 'longitude': '78.5', 'location': '38.2,78.5'}\n",
      "Created Structure: 38.2,78.5\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from pprint import pprint, pformat\n",
    "\n",
    "from django import forms\n",
    "from cases.forms import StructureForm\n",
    "\n",
    "def create_structure(data):\n",
    "    structure = handle_form(data, StructureForm)\n",
    "    print(f\"Created Structure: {structure}\")\n",
    "    return structure\n",
    "\n",
    "def process_csv(data, from_field_aliases):\n",
    "    \"\"\"Given a string representation of a CSV file, handle its contents\"\"\"\n",
    "    reader = gen_reader(data, from_field_aliases)\n",
    "    for row in reader:\n",
    "        print(f\"Row: {row}\")\n",
    "        # Convert all fields that have converters\n",
    "        converted = {}\n",
    "        for from_fields, converter in converters.items():\n",
    "            fields_to_convert = {field: row[field] for field in from_fields}\n",
    "            converted.update(converter(**fields_to_convert))\n",
    "        print(\"converted\", converted)\n",
    "        data = {**row, **converted}\n",
    "        print(\"data: \", data)\n",
    "        # Merge converted data with row data, overwriting any \"old\" data in the row\n",
    "        structure = create_structure(data)\n",
    "\n",
    "data1 = \"\"\"lat,long\n",
    "38.1,72.8\n",
    "\"\"\"\n",
    "\n",
    "data2 = \"\"\"LAT,LONG\n",
    "38.2,78.5\n",
    "\"\"\"\n",
    "\n",
    "compressed_from_field_aliases = {\n",
    "    # from_field: (alias1, alias2, ...)\n",
    "    \"latitude\": (\"lat\", \"LAT\"),\n",
    "    \"longitude\": (\"long\", \"LONG\"),\n",
    "}\n",
    "\n",
    "\n",
    "# Specify all custom converters here. Again, in cases where there is no conversion required,\n",
    "# we don't need to specify anything at all.\n",
    "converters = {\n",
    "    # (from_field1, from_field2, ...): converter_function(from_field1, from_field2, ...)\n",
    "    (\"latitude\", \"longitude\"): lambda latitude, longitude: {\"location\": f\"{latitude},{longitude}\"},\n",
    "}\n",
    "\n",
    "from_field_aliases = invert_aliases(compressed_from_field_aliases)\n",
    "print(\"And now to process the data, we do the same as before:\")\n",
    "for data in [data1, data2]:\n",
    "    process_csv(data, from_field_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is great, but what if want to process CSV files that contain data destined for multiple models? Our approach falls apart unless all fields in our models are unique in name. So, how can we fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'cases.forms.PersonForm'>: {'aliases': {'EMAIL': 'email',\n",
      "                                                'NAME': 'name',\n",
      "                                                'PHONE': 'phone',\n",
      "                                                'email': 'email',\n",
      "                                                'full_name': 'name',\n",
      "                                                'phone_number': 'phone'},\n",
      "                                    'converters': {}},\n",
      " <class 'cases.forms.CaseForm'>: {'aliases': {'CASE': 'case_num',\n",
      "                                              'case_num': 'case_num'},\n",
      "                                  'converters': {'case_num': <function <lambda> at 0x7ffb79df8d08>}},\n",
      " <class 'cases.forms.StructureForm'>: {'aliases': {'LAT': 'latitude',\n",
      "                                                   'LONG': 'longitude',\n",
      "                                                   'lat': 'latitude',\n",
      "                                                   'long': 'longitude'},\n",
      "                                       'converters': {('latitude', 'longitude'): <function <lambda> at 0x7ffb79df8e18>}}}\n"
     ]
    }
   ],
   "source": [
    "# Data from the first CSV file\n",
    "data1 = \"\"\"full_name,phone_number,email,case_num,lat,long\n",
    "Thomas,123456789,thomas@thomas.com,CASE#123123,38.1,72.8\n",
    "\"\"\"\n",
    "\n",
    "# Data from the second CSV file\n",
    "data2 = \"\"\"NAME,PHONE,EMAIL,CASE,LAT,LONG\n",
    "Bill,758586998,foo@bar.com,CASE#456456,38.2,78.5\n",
    "\"\"\"\n",
    "\n",
    "form_maps = {\n",
    "    CaseForm: {\n",
    "        \"aliases\": {\n",
    "            \"case_num\": (\"case_num\", \"CASE\"),\n",
    "        },\n",
    "        \"converters\": {\n",
    "            \"case_num\": lambda case_num: case_num.strip(\"CASE#\"),\n",
    "        }\n",
    "    },\n",
    "    PersonForm: {\n",
    "        \"aliases\": {\n",
    "            \"name\": (\"full_name\", \"NAME\"),\n",
    "            \"phone\": (\"phone_number\", \"PHONE\"),\n",
    "            \"email\": (\"email\", \"EMAIL\"),\n",
    "        },\n",
    "        \"converters\": {}\n",
    "    },\n",
    "    StructureForm: {\n",
    "        \"aliases\": {\n",
    "            \"latitude\": (\"lat\", \"LAT\"),\n",
    "            \"longitude\": (\"long\", \"LONG\"),\n",
    "        },\n",
    "        \"converters\": {\n",
    "            (\"latitude\", \"longitude\"): lambda latitude, longitude: {\"location\": f\"{latitude},{longitude}\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for form_class, info in form_maps.items():\n",
    "    info[\"aliases\"] = invert_aliases(info[\"aliases\"])\n",
    "    \n",
    "pprint(form_maps)\n",
    "\n",
    "def process_csv(data, from_field_aliases, form_maps):\n",
    "    \"\"\"Given a string representation of a CSV file, handle its contents\"\"\"\n",
    "    for row in csv.DictReader(StringIO(data)):\n",
    "        print(f\"Row: {row}\")\n",
    "        for form_class, info in form_maps.items():\n",
    "            # Convert all fields that have converters\n",
    "            converted = {}\n",
    "            data = {from_field: row[from_field] for from_field in info[\"aliases\"].items()}\n",
    "            print(\"data\", data)\n",
    "            for from_fields, converter in converters.items():\n",
    "                fields_to_convert = {field: row[field] for field in from_fields}\n",
    "                converted.update(converter(**fields_to_convert))\n",
    "            data = {**data, **converted}\n",
    "            handle_form(data, form_class)\n",
    "\n",
    "# for data in [data1, data2]:\n",
    "#     process_csv(data, from_field_aliases, form_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is getting really complicated. Let's introduce a few abstractions to help us out!\n",
    "\n",
    "First up is the concept of a `FieldMap`. This is a mapping of one or more \"from\" fields to one or more \"to\" fields. We've been representing these as dicts of `{ tuple : tuple }`, but wouldn't it be cleaner to bring all of this into a class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, but what does it _do_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': ('38.1', '72.8')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from django_import_data import FieldMap\n",
    "from django_import_data import OneToOneFieldMap, ManyToOneFieldMap\n",
    "\n",
    "# Create a ManyToOneFieldMap for our location field\n",
    "field_map = ManyToOneFieldMap(\n",
    "    from_fields={\n",
    "        \"latitude\": (\"lat\", \"LAT\"),\n",
    "        \"longitude\": (\"long\", \"LONG\"),\n",
    "    },\n",
    "    to_field=\"location\",\n",
    "    converter=lambda latitude, longitude: (latitude, longitude)\n",
    ")\n",
    "\n",
    "# This will take process aliases, then call convert_location with latitude and longitude as arguments\n",
    "field_map.render({\"lat\": \"38.1\", \"longitude\": \"72.8\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that makes sense... but what we really need is a way to group these FieldMaps together sensibly. So, we'll introduce FormMap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Case #456456 (None)\n",
      "Created Person Bill; 758586998; foo@bar.com\n",
      "Created Structure ('38.2', '78.5')\n"
     ]
    }
   ],
   "source": [
    "from django_import_data import FormMap\n",
    "from django_import_data import OneToOneFieldMap, ManyToOneFieldMap\n",
    "\n",
    "class CaseFormMap(FormMap):\n",
    "    form_class = CaseForm\n",
    "    field_maps = (\n",
    "        OneToOneFieldMap(\n",
    "            {\"case_num\": (\"CASE\",)}\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    def convert_case_num(self, case_num):\n",
    "        return case_num.strip(\"CASE#\")\n",
    "    \n",
    "class PersonFormMap(FormMap):\n",
    "    form_class = PersonForm\n",
    "    field_maps = (\n",
    "        OneToOneFieldMap({\"name\": (\"full_name\", \"NAME\")}),\n",
    "        OneToOneFieldMap({\"phone\": (\"phone_number\", \"PHONE\")}),\n",
    "        OneToOneFieldMap({\"email\": (\"EMAIL\",)}),\n",
    "    )\n",
    "    \n",
    "\n",
    "class StructureFormMap(FormMap):\n",
    "    form_class = StructureForm\n",
    "    field_maps = (\n",
    "        ManyToOneFieldMap(\n",
    "            from_fields={\n",
    "                \"latitude\": (\"lat\", \"LAT\"),\n",
    "                \"longitude\": (\"long\", \"LONG\"),\n",
    "            },\n",
    "            to_field=\"location\",\n",
    "            # This needs to be a string since the FieldMap is instantiated before the StructureFormMap,\n",
    "            # and thus the function won't be bound correctly\n",
    "            # We could also leave this out and rename the converter to convert_latitude_longitude\n",
    "            converter=\"convert_location\"\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    def convert_location(self, latitude, longitude):\n",
    "        return {\"location\": (latitude, longitude)}\n",
    "\n",
    "cfm = CaseFormMap()\n",
    "case = cfm.save({\"case_num\": \"456456\"})\n",
    "print(f\"Created Case {case}\")\n",
    "\n",
    "pfm = PersonFormMap()\n",
    "person = pfm.save({\"name\": \"Bill\", \"phone\": \"758586998\", \"email\": \"foo@bar.com\"})\n",
    "print(f\"Created Person {person}\")\n",
    "    \n",
    "sfm = StructureFormMap()\n",
    "structure = sfm.save({\"lat\": \"38.2\", \"longitude\": \"78.5\"})\n",
    "print(f\"Created Structure {structure}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
